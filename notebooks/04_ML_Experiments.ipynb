{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee51f71-f364-4c2e-b147-a530ea7cb0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Working Directory: C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\notebooks\n",
      "Random Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Importing Required Libraries\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adding src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Importing custom utilities\n",
    "from config import *\n",
    "from data_utils import retrieve_processed_datasets, load_resampled_data\n",
    "from model_utils import (\n",
    "    initialize_all_models,\n",
    "    train_single_model,\n",
    "    evaluate_model_predictions,\n",
    "    perform_cross_validation,\n",
    "    save_trained_model\n",
    ")\n",
    "from evaluation_utils import (\n",
    "    calculate_all_metrics,\n",
    "    create_confusion_matrix,\n",
    "    perform_statistical_significance_test,\n",
    "    print_statistical_test_results,\n",
    "    create_metrics_summary_table\n",
    ")\n",
    "\n",
    "# Setting visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Working Directory: {Path.cwd()}\")\n",
    "print(f\"Random Seed: {SEED_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d840602-b779-442d-8bb3-f0c589d4293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING TEST DATA\n",
      "======================================================================\n",
      "Loading processed data from C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\data\\processed...\n",
      "Datasets loaded successfully\n",
      "Training shape: (800000, 28)\n",
      "Testing shape: (200000, 28)\n",
      "\n",
      "Test set loaded (unchanged across all experiments):\n",
      "  Test features shape: (200000, 28)\n",
      "  Test labels shape: (200000,)\n",
      "\n",
      "Test Set Class Distribution:\n",
      "  Class 0: 94,065 (47.03%)\n",
      "  Class 1: 105,935 (52.97%)\n",
      "\n",
      "Note: This test set will be used to evaluate ALL 55 experiments\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Test Data (Unchanged)\n",
    "# Loading test data which remains constant across all experiments\n",
    "# One thing to remember is that test set is NEVER resampled\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING TEST DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading original processed datasets\n",
    "X_train_original, X_test, y_train_original, y_test = retrieve_processed_datasets(\n",
    "    file_prefix='higgs'\n",
    ")\n",
    "\n",
    "print(\"\\nTest set loaded (unchanged across all experiments):\")\n",
    "print(f\"  Test features shape: {X_test.shape}\")\n",
    "print(f\"  Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Displaying test set distribution\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "print(f\"\\nTest Set Class Distribution:\")\n",
    "for class_label, count in test_dist.items():\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    print(f\"  Class {int(class_label)}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\nNote: This test set will be used to evaluate ALL 55 experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab84ea5-de64-418f-8123-fc143ea54459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING BASELINE RESULTS\n",
      "======================================================================\n",
      "\n",
      "Baseline metrics loaded successfully!\n",
      "Number of baseline models: 5\n",
      "\n",
      "Baseline F1-Scores (No Resampling):\n",
      "  Logistic Regression: 0.6869\n",
      "  Random Forest: 0.7493\n",
      "  Xgboost: 0.7468\n",
      "  Svm: 0.4500\n",
      "  Mlp: 0.7701\n",
      "\n",
      "Best Baseline: mlp (F1=0.7701)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Baseline Results\n",
    "# Purpose: Loading baseline performance for comparison\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING BASELINE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading baseline metrics\n",
    "baseline_metrics_path = METRIC_OUTPUT / 'baseline' / 'baseline_metrics.json'\n",
    "\n",
    "with open(baseline_metrics_path, 'r', encoding='utf-8') as f:\n",
    "    baseline_metrics = json.load(f)\n",
    "\n",
    "print(\"\\nBaseline metrics loaded successfully!\")\n",
    "print(f\"Number of baseline models: {len(baseline_metrics)}\")\n",
    "\n",
    "# Displaying baseline F1-scores\n",
    "print(\"\\nBaseline F1-Scores (No Resampling):\")\n",
    "for model_name, metrics in baseline_metrics.items():\n",
    "    print(f\"  {model_name.replace('_', ' ').title()}: {metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Identifying best baseline\n",
    "best_baseline_model = max(baseline_metrics.items(), \n",
    "                          key=lambda x: x[1]['f1_score'])\n",
    "print(f\"\\nBest Baseline: {best_baseline_model[0]} (F1={best_baseline_model[1]['f1_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "069234f8-e60d-4c5d-9a66-9878198eeb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING RESAMPLING STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Resampling statistics loaded successfully!\n",
      "Number of resampling methods: 11\n",
      "\n",
      "Resampling Methods Available:\n",
      "   1. Baseline: 800,000 samples (Ratio: 0.888:1)\n",
      "   2. Random Oversampling: 847,476 samples (Ratio: 1.000:1)\n",
      "   3. Smote: 847,476 samples (Ratio: 1.000:1)\n",
      "   4. Borderline Smote: 847,476 samples (Ratio: 1.000:1)\n",
      "   5. Adasyn: 847,476 samples (Ratio: 1.000:1)\n",
      "   6. Random Undersampling: 752,524 samples (Ratio: 1.000:1)\n",
      "   7. Tomek Links: 751,637 samples (Ratio: 0.998:1)\n",
      "   8. Nearmiss: 752,524 samples (Ratio: 1.000:1)\n",
      "   9. Smote Tomek: 771,632 samples (Ratio: 1.000:1)\n",
      "  10. Smote Enn: 276,095 samples (Ratio: 0.858:1)\n",
      "  11. Class Weighting: 800,000 samples (Ratio: 0.888:1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Resampling Statistics\n",
    "# Loading resampling method information from previous notebook (03) \n",
    "# Statistics for each resampling method\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING RESAMPLING STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading resampling statistics\n",
    "resampling_stats_path = METRIC_OUTPUT / 'resampling' / 'resampling_statistics.json'\n",
    "\n",
    "with open(resampling_stats_path, 'r', encoding='utf-8') as f:\n",
    "    resampling_stats = json.load(f)\n",
    "\n",
    "print(\"\\nResampling statistics loaded successfully!\")\n",
    "print(f\"Number of resampling methods: {len(resampling_stats)}\")\n",
    "\n",
    "print(\"\\nResampling Methods Available:\")\n",
    "for i, method_name in enumerate(resampling_stats.keys(), 1):\n",
    "    method_info = resampling_stats[method_name]\n",
    "    print(f\"  {i:2d}. {method_name.replace('_', ' ').title()}: \"\n",
    "          f\"{method_info['n_samples']:,} samples \"\n",
    "          f\"(Ratio: {method_info['imbalance_ratio']:.3f}:1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1e9e79-16e1-4ffe-a614-ba90cf6238ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "Experimental Design:\n",
      "  Resampling Methods: 11\n",
      "  ML Models: 5\n",
      "  Total Experiments: 55\n",
      "  Cross-Validation Folds: 5\n",
      "  Total Model Trainings: 275\n",
      "\n",
      "Resampling Methods:\n",
      "  - baseline\n",
      "  - random_oversampling\n",
      "  - smote\n",
      "  - borderline_smote\n",
      "  - adasyn\n",
      "  - random_undersampling\n",
      "  - tomek_links\n",
      "  - nearmiss\n",
      "  - smote_tomek\n",
      "  - smote_enn\n",
      "  - class_weighting\n",
      "\n",
      "ML Models:\n",
      "  - logistic_regression\n",
      "  - random_forest\n",
      "  - xgboost\n",
      "  - svm\n",
      "  - mlp\n",
      "\n",
      "Experiment tracking initialized\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Defining Experiment Configuration\n",
    "# Setting up experimental design and tracking structure\n",
    "# Experiment matrix and results storage\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Defining resampling methods to test\n",
    "resampling_methods = list(resampling_stats.keys())\n",
    "\n",
    "# Defining models to test\n",
    "model_names = ['logistic_regression', 'random_forest', 'xgboost', 'svm', 'mlp']\n",
    "\n",
    "# Computing total experiments\n",
    "total_experiments = len(resampling_methods) * len(model_names)\n",
    "\n",
    "print(f\"\\nExperimental Design:\")\n",
    "print(f\"  Resampling Methods: {len(resampling_methods)}\")\n",
    "print(f\"  ML Models: {len(model_names)}\")\n",
    "print(f\"  Total Experiments: {total_experiments}\")\n",
    "print(f\"  Cross-Validation Folds: {FOLD_COUNT}\")\n",
    "print(f\"  Total Model Trainings: {total_experiments * FOLD_COUNT}\")\n",
    "\n",
    "print(f\"\\nResampling Methods:\")\n",
    "for method in resampling_methods:\n",
    "    print(f\"  - {method}\")\n",
    "\n",
    "print(f\"\\nML Models:\")\n",
    "for model in model_names:\n",
    "    print(f\"  - {model}\")\n",
    "\n",
    "# Initializing results storage\n",
    "experiment_results = []\n",
    "\n",
    "print(\"\\nExperiment tracking initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7fe320-425e-4b77-bb71-75385a22a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING MAIN EXPERIMENTS - PART 1\n",
      "======================================================================\n",
      "Processing: Baseline, Random Oversampling, SMOTE\n",
      "Experiments in this batch: 15\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: BASELINE\n",
      "======================================================================\n",
      "Loading resampled data: baseline\n",
      "  Loaded 800,000 samples\n",
      "  Features shape: (800000, 28)\n",
      "\n",
      "Dataset loaded: 800,000 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 1/55: baseline + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6869\n",
      "Time: 3.63s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 2/55: baseline + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7493\n",
      "Time: 77.58s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 3/55: baseline + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7468\n",
      "Time: 4.08s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 4/55: baseline + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.4500\n",
      "Time: 1222.91s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 5/55: baseline + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7701\n",
      "Time: 236.71s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: RANDOM_OVERSAMPLING\n",
      "======================================================================\n",
      "Loading resampled data: random_oversampling\n",
      "  Loaded 847,476 samples\n",
      "  Features shape: (847476, 28)\n",
      "\n",
      "Dataset loaded: 847,476 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 6/55: random_oversampling + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6609\n",
      "Time: 3.73s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 7/55: random_oversampling + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7431\n",
      "Time: 80.98s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 8/55: random_oversampling + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7374\n",
      "Time: 4.66s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 9/55: random_oversampling + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.5513\n",
      "Time: 1285.84s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 10/55: random_oversampling + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7628\n",
      "Time: 182.44s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: SMOTE\n",
      "======================================================================\n",
      "Loading resampled data: smote\n",
      "  Loaded 847,476 samples\n",
      "  Features shape: (847476, 28)\n",
      "\n",
      "Dataset loaded: 847,476 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 11/55: smote + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6607\n",
      "Time: 3.29s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 12/55: smote + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7417\n",
      "Time: 75.64s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 13/55: smote + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7393\n",
      "Time: 3.70s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 14/55: smote + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.5461\n",
      "Time: 1235.04s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 15/55: smote + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7592\n",
      "Time: 199.93s\n",
      "\n",
      "======================================================================\n",
      "BATCH 1 COMPLETED: 15/55 experiments\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Main Experiment Loop - Part 1 (Baseline + ROS + SMOTE)\n",
    "# Running first 3 resampling methods × 5 models = 15 experiments\n",
    "# Methods: baseline, random_oversampling, smote\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING MAIN EXPERIMENTS - PART 1\")\n",
    "print(\"=\"*70)\n",
    "print(\"Processing: Baseline, Random Oversampling, SMOTE\")\n",
    "print(f\"Experiments in this batch: 15\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Methods for this batch\n",
    "batch_1_methods = ['baseline', 'random_oversampling', 'smote']\n",
    "\n",
    "experiment_counter = 0\n",
    "\n",
    "for method_name in batch_1_methods:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESAMPLING METHOD: {method_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Loading resampled data\n",
    "    if method_name == 'class_weighting':\n",
    "        # Class weighting uses original data\n",
    "        X_resampled = X_train_original.copy()\n",
    "        y_resampled = y_train_original.copy()\n",
    "        use_weights = True\n",
    "        class_weights = resampling_stats[method_name].get('weights', None)\n",
    "    else:\n",
    "        # Loading resampled dataset\n",
    "        X_resampled, y_resampled = load_resampled_data(\n",
    "            method_name=method_name,\n",
    "            data_dir=RESAMPLED_DIR\n",
    "        )\n",
    "        use_weights = False\n",
    "        class_weights = None\n",
    "    \n",
    "    print(f\"\\nDataset loaded: {len(X_resampled):,} samples\")\n",
    "    \n",
    "    # Training all models on this resampled data\n",
    "    for model_name in model_names:\n",
    "        experiment_counter += 1\n",
    "        \n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Experiment {experiment_counter}/{total_experiments}: \"\n",
    "              f\"{method_name} + {model_name}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        # Recording experiment start time\n",
    "        exp_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Initializing model\n",
    "            models = initialize_all_models(\n",
    "                use_class_weights=use_weights,\n",
    "                class_weight_dict=class_weights\n",
    "            )\n",
    "            model = models[model_name]\n",
    "            \n",
    "            # Training model\n",
    "            trained_model, train_time = train_single_model(\n",
    "                model=model,\n",
    "                X_train=X_resampled,\n",
    "                y_train=y_resampled,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Evaluating on test set\n",
    "            eval_results = evaluate_model_predictions(\n",
    "                model=trained_model,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Computing metrics\n",
    "            metrics = calculate_all_metrics(\n",
    "                y_true=y_test,\n",
    "                y_pred=eval_results['y_pred'],\n",
    "                y_proba=eval_results['y_proba']\n",
    "            )\n",
    "            \n",
    "            # Computing total experiment time\n",
    "            exp_time = time.time() - exp_start_time\n",
    "            \n",
    "            # Storing results\n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'auc_roc': metrics['auc_roc'],\n",
    "                'auc_pr': metrics['auc_pr'],\n",
    "                'g_mean': metrics['g_mean'],\n",
    "                'mcc': metrics['mcc'],\n",
    "                'training_time': train_time,\n",
    "                'experiment_time': exp_time,\n",
    "                'dataset_size': len(X_resampled),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            experiment_results.append(result_row)\n",
    "            \n",
    "            print(f\"Status: SUCCESS\")\n",
    "            print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "            print(f\"Time: {exp_time:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Status: FAILED - {str(e)}\")\n",
    "            \n",
    "            # Recording failure\n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            experiment_results.append(result_row)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BATCH 1 COMPLETED: {experiment_counter}/{total_experiments} experiments\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2facdf-8318-4ab4-8ee9-35351fa8b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING MAIN EXPERIMENTS - PART 2\n",
      "======================================================================\n",
      "Processing: Borderline-SMOTE, ADASYN\n",
      "Experiments in this batch: 10\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: BORDERLINE_SMOTE\n",
      "======================================================================\n",
      "Loading resampled data: borderline_smote\n",
      "  Loaded 847,476 samples\n",
      "  Features shape: (847476, 28)\n",
      "\n",
      "Dataset loaded: 847,476 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 16/55: borderline_smote + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6569\n",
      "Time: 9.44s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 17/55: borderline_smote + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7382\n",
      "Time: 77.00s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 18/55: borderline_smote + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7364\n",
      "Time: 3.65s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 19/55: borderline_smote + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6242\n",
      "Time: 1232.46s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 20/55: borderline_smote + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7603\n",
      "Time: 185.01s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: ADASYN\n",
      "======================================================================\n",
      "Loading resampled data: adasyn\n",
      "  Loaded 847,476 samples\n",
      "  Features shape: (847476, 28)\n",
      "\n",
      "Dataset loaded: 847,476 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 21/55: adasyn + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6607\n",
      "Time: 3.32s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 22/55: adasyn + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7417\n",
      "Time: 75.53s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 23/55: adasyn + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7393\n",
      "Time: 3.69s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 24/55: adasyn + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.5461\n",
      "Time: 1230.11s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 25/55: adasyn + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7592\n",
      "Time: 197.58s\n",
      "\n",
      "======================================================================\n",
      "BATCH 2 COMPLETED: 25/55 experiments\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main Experiment Loop - Part 2 (Borderline-SMOTE + ADASYN)\n",
    "# Running next 2 resampling methods × 5 models = 10 experiments\n",
    "# Methods: borderline_smote, adasyn\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING MAIN EXPERIMENTS - PART 2\")\n",
    "print(\"=\"*70)\n",
    "print(\"Processing: Borderline-SMOTE, ADASYN\")\n",
    "print(f\"Experiments in this batch: 10\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Methods for this batch\n",
    "batch_2_methods = ['borderline_smote', 'adasyn']\n",
    "\n",
    "for method_name in batch_2_methods:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESAMPLING METHOD: {method_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Loading resampled data\n",
    "    X_resampled, y_resampled = load_resampled_data(\n",
    "        method_name=method_name,\n",
    "        data_dir=RESAMPLED_DIR\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset loaded: {len(X_resampled):,} samples\")\n",
    "    \n",
    "    # Training all models\n",
    "    for model_name in model_names:\n",
    "        experiment_counter += 1\n",
    "        \n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Experiment {experiment_counter}/{total_experiments}: \"\n",
    "              f\"{method_name} + {model_name}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        exp_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            models = initialize_all_models(use_class_weights=False)\n",
    "            model = models[model_name]\n",
    "            \n",
    "            trained_model, train_time = train_single_model(\n",
    "                model=model,\n",
    "                X_train=X_resampled,\n",
    "                y_train=y_resampled,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            eval_results = evaluate_model_predictions(\n",
    "                model=trained_model,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            metrics = calculate_all_metrics(\n",
    "                y_true=y_test,\n",
    "                y_pred=eval_results['y_pred'],\n",
    "                y_proba=eval_results['y_proba']\n",
    "            )\n",
    "            \n",
    "            exp_time = time.time() - exp_start_time\n",
    "            \n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'auc_roc': metrics['auc_roc'],\n",
    "                'auc_pr': metrics['auc_pr'],\n",
    "                'g_mean': metrics['g_mean'],\n",
    "                'mcc': metrics['mcc'],\n",
    "                'training_time': train_time,\n",
    "                'experiment_time': exp_time,\n",
    "                'dataset_size': len(X_resampled),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            experiment_results.append(result_row)\n",
    "            \n",
    "            print(f\"Status: SUCCESS\")\n",
    "            print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "            print(f\"Time: {exp_time:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Status: FAILED - {str(e)}\")\n",
    "            \n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            experiment_results.append(result_row)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BATCH 2 COMPLETED: {experiment_counter}/{total_experiments} experiments\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9980a9-2d64-41b7-a64f-c384791bfb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING MAIN EXPERIMENTS - PART 3\n",
      "======================================================================\n",
      "Processing: Random Undersampling, Tomek Links, NearMiss\n",
      "Experiments in this batch: 15\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: RANDOM_UNDERSAMPLING\n",
      "======================================================================\n",
      "Loading resampled data: random_undersampling\n",
      "  Loaded 752,524 samples\n",
      "  Features shape: (752524, 28)\n",
      "\n",
      "Dataset loaded: 752,524 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 26/55: random_undersampling + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6610\n",
      "Time: 3.39s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 27/55: random_undersampling + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7388\n",
      "Time: 65.44s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 28/55: random_undersampling + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7373\n",
      "Time: 3.26s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 29/55: random_undersampling + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.5241\n",
      "Time: 1066.51s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 30/55: random_undersampling + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7624\n",
      "Time: 170.25s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: TOMEK_LINKS\n",
      "======================================================================\n",
      "Loading resampled data: tomek_links\n",
      "  Loaded 751,637 samples\n",
      "  Features shape: (751637, 28)\n",
      "\n",
      "Dataset loaded: 751,637 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 31/55: tomek_links + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6559\n",
      "Time: 3.21s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 32/55: tomek_links + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7358\n",
      "Time: 65.35s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 33/55: tomek_links + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7340\n",
      "Time: 3.35s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 34/55: tomek_links + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.5438\n",
      "Time: 1122.88s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 35/55: tomek_links + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7603\n",
      "Time: 148.36s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: NEARMISS\n",
      "======================================================================\n",
      "Loading resampled data: nearmiss\n",
      "  Loaded 752,524 samples\n",
      "  Features shape: (752524, 28)\n",
      "\n",
      "Dataset loaded: 752,524 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 36/55: nearmiss + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6697\n",
      "Time: 3.52s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 37/55: nearmiss + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7191\n",
      "Time: 66.02s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 38/55: nearmiss + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7165\n",
      "Time: 3.16s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 39/55: nearmiss + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.5742\n",
      "Time: 1059.62s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 40/55: nearmiss + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7372\n",
      "Time: 183.21s\n",
      "\n",
      "======================================================================\n",
      "BATCH 3 COMPLETED: 40/55 experiments\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Main Experiment Loop - Part 3 (Undersampling Methods)\n",
    "# Running 3 undersampling methods × 5 models = 15 experiments\n",
    "# Methods: random_undersampling, tomek_links, nearmiss\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING MAIN EXPERIMENTS - PART 3\")\n",
    "print(\"=\"*70)\n",
    "print(\"Processing: Random Undersampling, Tomek Links, NearMiss\")\n",
    "print(f\"Experiments in this batch: 15\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Methods for this batch\n",
    "batch_3_methods = ['random_undersampling', 'tomek_links', 'nearmiss']\n",
    "\n",
    "for method_name in batch_3_methods:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESAMPLING METHOD: {method_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Loading resampled data\n",
    "    X_resampled, y_resampled = load_resampled_data(\n",
    "        method_name=method_name,\n",
    "        data_dir=RESAMPLED_DIR\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset loaded: {len(X_resampled):,} samples\")\n",
    "    \n",
    "    # Training all models\n",
    "    for model_name in model_names:\n",
    "        experiment_counter += 1\n",
    "        \n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Experiment {experiment_counter}/{total_experiments}: \"\n",
    "              f\"{method_name} + {model_name}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        exp_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            models = initialize_all_models(use_class_weights=False)\n",
    "            model = models[model_name]\n",
    "            \n",
    "            trained_model, train_time = train_single_model(\n",
    "                model=model,\n",
    "                X_train=X_resampled,\n",
    "                y_train=y_resampled,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            eval_results = evaluate_model_predictions(\n",
    "                model=trained_model,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            metrics = calculate_all_metrics(\n",
    "                y_true=y_test,\n",
    "                y_pred=eval_results['y_pred'],\n",
    "                y_proba=eval_results['y_proba']\n",
    "            )\n",
    "            \n",
    "            exp_time = time.time() - exp_start_time\n",
    "            \n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'auc_roc': metrics['auc_roc'],\n",
    "                'auc_pr': metrics['auc_pr'],\n",
    "                'g_mean': metrics['g_mean'],\n",
    "                'mcc': metrics['mcc'],\n",
    "                'training_time': train_time,\n",
    "                'experiment_time': exp_time,\n",
    "                'dataset_size': len(X_resampled),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            experiment_results.append(result_row)\n",
    "            \n",
    "            print(f\"Status: SUCCESS\")\n",
    "            print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "            print(f\"Time: {exp_time:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Status: FAILED - {str(e)}\")\n",
    "            \n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            experiment_results.append(result_row)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"BATCH 3 COMPLETED: {experiment_counter}/{total_experiments} experiments\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541de80e-c6d8-415e-aa26-9527d2768e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STARTING MAIN EXPERIMENTS - PART 4 (FINAL BATCH)\n",
      "======================================================================\n",
      "Processing: SMOTE+Tomek, SMOTE+ENN, Class Weighting\n",
      "Experiments in this batch: 15\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: SMOTE_TOMEK\n",
      "======================================================================\n",
      "Loading resampled data: smote_tomek\n",
      "  Loaded 771,632 samples\n",
      "  Features shape: (771632, 28)\n",
      "\n",
      "Dataset loaded: 771,632 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 41/55: smote_tomek + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6612\n",
      "Time: 3.48s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 42/55: smote_tomek + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7406\n",
      "Time: 69.86s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 43/55: smote_tomek + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7392\n",
      "Time: 3.39s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 44/55: smote_tomek + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.4304\n",
      "Time: 1156.34s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 45/55: smote_tomek + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7633\n",
      "Time: 198.85s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: SMOTE_ENN\n",
      "======================================================================\n",
      "Loading resampled data: smote_enn\n",
      "  Loaded 276,095 samples\n",
      "  Features shape: (276095, 28)\n",
      "\n",
      "Dataset loaded: 276,095 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 46/55: smote_enn + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6417\n",
      "Time: 2.84s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 47/55: smote_enn + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7184\n",
      "Time: 20.45s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 48/55: smote_enn + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7233\n",
      "Time: 1.50s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 49/55: smote_enn + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6567\n",
      "Time: 358.67s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 50/55: smote_enn + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7277\n",
      "Time: 50.63s\n",
      "\n",
      "======================================================================\n",
      "RESAMPLING METHOD: CLASS_WEIGHTING\n",
      "======================================================================\n",
      "\n",
      "Dataset loaded: 800,000 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 51/55: class_weighting + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: FAILED - The classes, [0, 1], are not in class_weight\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 52/55: class_weighting + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: FAILED - The classes, [0, 1], are not in class_weight\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 53/55: class_weighting + xgboost\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7468\n",
      "Time: 3.43s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 54/55: class_weighting + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: FAILED - The classes, [0, 1], are not in class_weight\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Experiment 55/55: class_weighting + mlp\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7701\n",
      "Time: 231.12s\n",
      "\n",
      "======================================================================\n",
      "ALL EXPERIMENTS COMPLETED: 55/55\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Main Experiment Loop - Part 4 (Combination Methods + Class Weights)\n",
    "# Purpose: Running final 3 methods × 5 models = 15 experiments\n",
    "# Methods: smote_tomek, smote_enn, class_weighting\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING MAIN EXPERIMENTS - PART 4 (FINAL BATCH)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Processing: SMOTE+Tomek, SMOTE+ENN, Class Weighting\")\n",
    "print(f\"Experiments in this batch: 15\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Methods for this batch\n",
    "batch_4_methods = ['smote_tomek', 'smote_enn', 'class_weighting']\n",
    "\n",
    "for method_name in batch_4_methods:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESAMPLING METHOD: {method_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Loading resampled data\n",
    "    if method_name == 'class_weighting':\n",
    "        X_resampled = X_train_original.copy()\n",
    "        y_resampled = y_train_original.copy()\n",
    "        use_weights = True\n",
    "        class_weights = resampling_stats[method_name].get('weights', None)\n",
    "    else:\n",
    "        X_resampled, y_resampled = load_resampled_data(\n",
    "            method_name=method_name,\n",
    "            data_dir=RESAMPLED_DIR\n",
    "        )\n",
    "        use_weights = False\n",
    "        class_weights = None\n",
    "    \n",
    "    print(f\"\\nDataset loaded: {len(X_resampled):,} samples\")\n",
    "    \n",
    "    # Training all models\n",
    "    for model_name in model_names:\n",
    "        experiment_counter += 1\n",
    "        \n",
    "        print(f\"\\n{'-'*70}\")\n",
    "        print(f\"Experiment {experiment_counter}/{total_experiments}: \"\n",
    "              f\"{method_name} + {model_name}\")\n",
    "        print(f\"{'-'*70}\")\n",
    "        \n",
    "        exp_start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            models = initialize_all_models(\n",
    "                use_class_weights=use_weights,\n",
    "                class_weight_dict=class_weights\n",
    "            )\n",
    "            model = models[model_name]\n",
    "            \n",
    "            trained_model, train_time = train_single_model(\n",
    "                model=model,\n",
    "                X_train=X_resampled,\n",
    "                y_train=y_resampled,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            eval_results = evaluate_model_predictions(\n",
    "                model=trained_model,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                model_name=f\"{method_name}_{model_name}\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            metrics = calculate_all_metrics(\n",
    "                y_true=y_test,\n",
    "                y_pred=eval_results['y_pred'],\n",
    "                y_proba=eval_results['y_proba']\n",
    "            )\n",
    "            \n",
    "            exp_time = time.time() - exp_start_time\n",
    "            \n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'accuracy': metrics['accuracy'],\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'f1_score': metrics['f1_score'],\n",
    "                'auc_roc': metrics['auc_roc'],\n",
    "                'auc_pr': metrics['auc_pr'],\n",
    "                'g_mean': metrics['g_mean'],\n",
    "                'mcc': metrics['mcc'],\n",
    "                'training_time': train_time,\n",
    "                'experiment_time': exp_time,\n",
    "                'dataset_size': len(X_resampled),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            experiment_results.append(result_row)\n",
    "            \n",
    "            print(f\"Status: SUCCESS\")\n",
    "            print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "            print(f\"Time: {exp_time:.2f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Status: FAILED - {str(e)}\")\n",
    "            \n",
    "            result_row = {\n",
    "                'resampling_method': method_name,\n",
    "                'model': model_name,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            experiment_results.append(result_row)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ALL EXPERIMENTS COMPLETED: {experiment_counter}/{total_experiments}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f104e4dd-190b-49a3-9552-07cdc12690e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RE-RUNNING FAILED CLASS WEIGHTING EXPERIMENTS\n",
      "======================================================================\n",
      "\n",
      "Class weights: {np.int64(0): np.float64(1.063089017758902), np.int64(1): np.float64(0.9439795345236915)}\n",
      "Dataset: 800,000 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Re-running: class_weighting + logistic_regression\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.6608\n",
      "Time: 3.80s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Re-running: class_weighting + random_forest\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.7430\n",
      "Time: 71.76s\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Re-running: class_weighting + svm\n",
      "----------------------------------------------------------------------\n",
      "Status: SUCCESS\n",
      "F1-Score: 0.0000\n",
      "Time: 1137.79s\n",
      "\n",
      "======================================================================\n",
      "CLASS WEIGHTING EXPERIMENTS FIXED!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 9b: Re-runnig Failed Class Weighting Experiments\n",
    "# Fixing the 3 failed class_weighting experiments\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RE-RUNNING FAILED CLASS WEIGHTING EXPERIMENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading original training data\n",
    "X_resampled = X_train_original.copy()\n",
    "y_resampled = y_train_original.copy()\n",
    "\n",
    "# Recalculating class weights with correct integer keys\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_train_original)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_train_original)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "print(f\"\\nClass weights: {class_weights}\")\n",
    "print(f\"Dataset: {len(X_resampled):,} samples\")\n",
    "\n",
    "# Models that failed\n",
    "failed_models = ['logistic_regression', 'random_forest', 'svm']\n",
    "\n",
    "for model_name in failed_models:\n",
    "    print(f\"\\n{'-'*70}\")\n",
    "    print(f\"Re-running: class_weighting + {model_name}\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    \n",
    "    exp_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Initialize model with class weights\n",
    "        models = initialize_all_models(\n",
    "            use_class_weights=True,\n",
    "            class_weight_dict=class_weights\n",
    "        )\n",
    "        model = models[model_name]\n",
    "        \n",
    "        # Train\n",
    "        trained_model, train_time = train_single_model(\n",
    "            model=model,\n",
    "            X_train=X_resampled,\n",
    "            y_train=y_resampled,\n",
    "            model_name=f\"class_weighting_{model_name}\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_results = evaluate_model_predictions(\n",
    "            model=trained_model,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            model_name=f\"class_weighting_{model_name}\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Metrics\n",
    "        metrics = calculate_all_metrics(\n",
    "            y_true=y_test,\n",
    "            y_pred=eval_results['y_pred'],\n",
    "            y_proba=eval_results['y_proba']\n",
    "        )\n",
    "        \n",
    "        exp_time = time.time() - exp_start_time\n",
    "        \n",
    "        # Update the failed result in experiment_results\n",
    "        for i, result in enumerate(experiment_results):\n",
    "            if (result['resampling_method'] == 'class_weighting' and \n",
    "                result['model'] == model_name and \n",
    "                result.get('status') == 'failed'):\n",
    "                \n",
    "                # Replace failed result with successful one\n",
    "                experiment_results[i] = {\n",
    "                    'resampling_method': 'class_weighting',\n",
    "                    'model': model_name,\n",
    "                    'accuracy': metrics['accuracy'],\n",
    "                    'precision': metrics['precision'],\n",
    "                    'recall': metrics['recall'],\n",
    "                    'f1_score': metrics['f1_score'],\n",
    "                    'auc_roc': metrics['auc_roc'],\n",
    "                    'auc_pr': metrics['auc_pr'],\n",
    "                    'g_mean': metrics['g_mean'],\n",
    "                    'mcc': metrics['mcc'],\n",
    "                    'training_time': train_time,\n",
    "                    'experiment_time': exp_time,\n",
    "                    'dataset_size': len(X_resampled),\n",
    "                    'status': 'success'\n",
    "                }\n",
    "                break\n",
    "        \n",
    "        print(f\"Status: SUCCESS\")\n",
    "        print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "        print(f\"Time: {exp_time:.2f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Status: STILL FAILED - {str(e)}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CLASS WEIGHTING EXPERIMENTS FIXED!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89e662-f25f-4f8e-afc6-853c4ddb2134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Higgs Project)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
