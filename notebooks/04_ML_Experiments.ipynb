{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee51f71-f364-4c2e-b147-a530ea7cb0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Working Directory: C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\notebooks\n",
      "Random Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Importing Required Libraries\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adding src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Importing custom utilities\n",
    "from config import *\n",
    "from data_utils import retrieve_processed_datasets, load_resampled_data\n",
    "from model_utils import (\n",
    "    initialize_all_models,\n",
    "    train_single_model,\n",
    "    evaluate_model_predictions,\n",
    "    perform_cross_validation,\n",
    "    save_trained_model\n",
    ")\n",
    "from evaluation_utils import (\n",
    "    calculate_all_metrics,\n",
    "    create_confusion_matrix,\n",
    "    perform_statistical_significance_test,\n",
    "    print_statistical_test_results,\n",
    "    create_metrics_summary_table\n",
    ")\n",
    "\n",
    "# Setting visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Working Directory: {Path.cwd()}\")\n",
    "print(f\"Random Seed: {SEED_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d840602-b779-442d-8bb3-f0c589d4293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING TEST DATA\n",
      "======================================================================\n",
      "Loading processed data from C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\data\\processed...\n",
      "Datasets loaded successfully\n",
      "Training shape: (800000, 28)\n",
      "Testing shape: (200000, 28)\n",
      "\n",
      "Test set loaded (unchanged across all experiments):\n",
      "  Test features shape: (200000, 28)\n",
      "  Test labels shape: (200000,)\n",
      "\n",
      "Test Set Class Distribution:\n",
      "  Class 0: 94,065 (47.03%)\n",
      "  Class 1: 105,935 (52.97%)\n",
      "\n",
      "Note: This test set will be used to evaluate ALL 55 experiments\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Test Data (Unchanged)\n",
    "# Loading test data which remains constant across all experiments\n",
    "# One thing to remember is that test set is NEVER resampled\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING TEST DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading original processed datasets\n",
    "X_train_original, X_test, y_train_original, y_test = retrieve_processed_datasets(\n",
    "    file_prefix='higgs'\n",
    ")\n",
    "\n",
    "print(\"\\nTest set loaded (unchanged across all experiments):\")\n",
    "print(f\"  Test features shape: {X_test.shape}\")\n",
    "print(f\"  Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Displaying test set distribution\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "print(f\"\\nTest Set Class Distribution:\")\n",
    "for class_label, count in test_dist.items():\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    print(f\"  Class {int(class_label)}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\nNote: This test set will be used to evaluate ALL 55 experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab84ea5-de64-418f-8123-fc143ea54459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING BASELINE RESULTS\n",
      "======================================================================\n",
      "\n",
      "Baseline metrics loaded successfully!\n",
      "Number of baseline models: 5\n",
      "\n",
      "Baseline F1-Scores (No Resampling):\n",
      "  Logistic Regression: 0.6869\n",
      "  Random Forest: 0.7493\n",
      "  Xgboost: 0.7468\n",
      "  Svm: 0.4500\n",
      "  Mlp: 0.7701\n",
      "\n",
      "Best Baseline: mlp (F1=0.7701)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Baseline Results\n",
    "# Purpose: Loading baseline performance for comparison\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING BASELINE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading baseline metrics\n",
    "baseline_metrics_path = METRIC_OUTPUT / 'baseline' / 'baseline_metrics.json'\n",
    "\n",
    "with open(baseline_metrics_path, 'r', encoding='utf-8') as f:\n",
    "    baseline_metrics = json.load(f)\n",
    "\n",
    "print(\"\\nBaseline metrics loaded successfully!\")\n",
    "print(f\"Number of baseline models: {len(baseline_metrics)}\")\n",
    "\n",
    "# Displaying baseline F1-scores\n",
    "print(\"\\nBaseline F1-Scores (No Resampling):\")\n",
    "for model_name, metrics in baseline_metrics.items():\n",
    "    print(f\"  {model_name.replace('_', ' ').title()}: {metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Identifying best baseline\n",
    "best_baseline_model = max(baseline_metrics.items(), \n",
    "                          key=lambda x: x[1]['f1_score'])\n",
    "print(f\"\\nBest Baseline: {best_baseline_model[0]} (F1={best_baseline_model[1]['f1_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "069234f8-e60d-4c5d-9a66-9878198eeb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING RESAMPLING STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Resampling statistics loaded successfully!\n",
      "Number of resampling methods: 11\n",
      "\n",
      "Resampling Methods Available:\n",
      "   1. Baseline: 800,000 samples (Ratio: 0.888:1)\n",
      "   2. Random Oversampling: 847,476 samples (Ratio: 1.000:1)\n",
      "   3. Smote: 847,476 samples (Ratio: 1.000:1)\n",
      "   4. Borderline Smote: 847,476 samples (Ratio: 1.000:1)\n",
      "   5. Adasyn: 847,476 samples (Ratio: 1.000:1)\n",
      "   6. Random Undersampling: 752,524 samples (Ratio: 1.000:1)\n",
      "   7. Tomek Links: 751,637 samples (Ratio: 0.998:1)\n",
      "   8. Nearmiss: 752,524 samples (Ratio: 1.000:1)\n",
      "   9. Smote Tomek: 771,632 samples (Ratio: 1.000:1)\n",
      "  10. Smote Enn: 276,095 samples (Ratio: 0.858:1)\n",
      "  11. Class Weighting: 800,000 samples (Ratio: 0.888:1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Resampling Statistics\n",
    "# Loading resampling method information from previous notebook (03) \n",
    "# Statistics for each resampling method\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING RESAMPLING STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading resampling statistics\n",
    "resampling_stats_path = METRIC_OUTPUT / 'resampling' / 'resampling_statistics.json'\n",
    "\n",
    "with open(resampling_stats_path, 'r', encoding='utf-8') as f:\n",
    "    resampling_stats = json.load(f)\n",
    "\n",
    "print(\"\\nResampling statistics loaded successfully!\")\n",
    "print(f\"Number of resampling methods: {len(resampling_stats)}\")\n",
    "\n",
    "print(\"\\nResampling Methods Available:\")\n",
    "for i, method_name in enumerate(resampling_stats.keys(), 1):\n",
    "    method_info = resampling_stats[method_name]\n",
    "    print(f\"  {i:2d}. {method_name.replace('_', ' ').title()}: \"\n",
    "          f\"{method_info['n_samples']:,} samples \"\n",
    "          f\"(Ratio: {method_info['imbalance_ratio']:.3f}:1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e9e79-16e1-4ffe-a614-ba90cf6238ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Higgs Project)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
