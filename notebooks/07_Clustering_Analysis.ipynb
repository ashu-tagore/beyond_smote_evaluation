{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb1e532-3a62-4621-a036-d4255086e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Working Directory: C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\notebooks\n",
      "Scikit-learn clustering modules loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Importing Required Libraries\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clustering imports\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score\n",
    ")\n",
    "\n",
    "# Visualization imports\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Adding src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Importing custom utilities\n",
    "from config import *\n",
    "from data_utils import retrieve_processed_datasets\n",
    "\n",
    "# Setting visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Working Directory: {Path.cwd()}\")\n",
    "print(f\"Scikit-learn clustering modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c0b979-807b-45ee-a1f8-9e320aa59a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TASK D: CLUSTERING ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Clustering Objectives:\n",
      "  1. Discover natural groupings in particle collision events\n",
      "  2. Identify event patterns beyond binary classification\n",
      "  3. Understand physics-based event characteristics\n",
      "  4. Validate clusters against known signal/background labels\n",
      "\n",
      "Clustering Approaches:\n",
      "  - K-Means: Partition-based clustering\n",
      "  - Hierarchical: Agglomerative clustering\n",
      "  - DBSCAN: Density-based clustering\n",
      "\n",
      "Why Clustering for HIGGS Data?\n",
      "  - Discover sub-categories within signal/background\n",
      "  - Identify rare event types\n",
      "  - Understand event topology patterns\n",
      "  - Validate supervised classification boundaries\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Problem Introduction - Clustering Analysis\n",
    "# Defining clustering objectives for particle physics data\n",
    "# Approach: Unsupervised pattern discovery in collision events\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TASK D: CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nClustering Objectives:\")\n",
    "print(\"  1. Discover natural groupings in particle collision events\")\n",
    "print(\"  2. Identify event patterns beyond binary classification\")\n",
    "print(\"  3. Understand physics-based event characteristics\")\n",
    "print(\"  4. Validate clusters against known signal/background labels\")\n",
    "\n",
    "print(\"\\nClustering Approaches:\")\n",
    "print(\"  - K-Means: Partition-based clustering\")\n",
    "print(\"  - Hierarchical: Agglomerative clustering\")\n",
    "print(\"  - DBSCAN: Density-based clustering\")\n",
    "\n",
    "print(\"\\nWhy Clustering for HIGGS Data?\")\n",
    "print(\"  - Discover sub-categories within signal/background\")\n",
    "print(\"  - Identify rare event types\")\n",
    "print(\"  - Understand event topology patterns\")\n",
    "print(\"  - Validate supervised classification boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a696d3d5-bd9d-4404-94ec-0afe3c44a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA LOADING & PREPARATION FOR CLUSTERING\n",
      "======================================================================\n",
      "Loading processed data from C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\data\\processed...\n",
      "Datasets loaded successfully\n",
      "Training shape: (800000, 28)\n",
      "Testing shape: (200000, 28)\n",
      "\n",
      "Full dataset loaded:\n",
      "  Training: (800000, 28)\n",
      "  Test: (200000, 28)\n",
      "\n",
      "Sampling 50,000 events for clustering analysis\n",
      "   (Clustering is O(n²) - full dataset would take hours)\n",
      "\n",
      "Clustering Dataset (before scaling):\n",
      "  Shape: (50000, 28)\n",
      "  Features: 28\n",
      "  Samples: 50,000\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Loading and Preparing Data for Clustering\n",
    "# Loading processed data, sampling, and SCALING features\n",
    "# Feature scaling is CRITICAL for distance-based clustering\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA LOADING & PREPARATION FOR CLUSTERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loading processed data\n",
    "X_full, X_test_full, y_full, y_test_full = retrieve_processed_datasets(\n",
    "    file_prefix='higgs'\n",
    ")\n",
    "\n",
    "print(\"\\nFull dataset loaded:\")\n",
    "print(f\"  Training: {X_full.shape}\")\n",
    "print(f\"  Test: {X_test_full.shape}\")\n",
    "\n",
    "# Sampling for computational efficiency\n",
    "# Clustering on 800K samples is very slow so I am using representative sample\n",
    "CLUSTER_SAMPLE_SIZE = 50000  # 50K samples for clustering\n",
    "\n",
    "print(f\"\\nSampling {CLUSTER_SAMPLE_SIZE:,} events for clustering analysis\")\n",
    "print(\"   (Clustering is O(n²) - full dataset would take hours)\")\n",
    "\n",
    "# Stratified sampling to preserve class distribution\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cluster, _, y_cluster, _ = train_test_split(\n",
    "    X_full, y_full,\n",
    "    train_size=CLUSTER_SAMPLE_SIZE,\n",
    "    random_state=SEED_VALUE,\n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"\\nClustering Dataset (before scaling):\")\n",
    "print(f\"  Shape: {X_cluster.shape}\")\n",
    "print(f\"  Features: {X_cluster.shape[1]}\")\n",
    "print(f\"  Samples: {X_cluster.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d231d-04b4-4864-bb82-d8d2ef6109f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Higgs Project)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
