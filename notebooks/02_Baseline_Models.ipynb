{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478fba8f-3d70-41a0-a3a2-c68148c6109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Working Directory: C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\notebooks\n",
      "Random Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Importing Required Libraries\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adding src directory to path for importing custom modules\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Importing custom utility functions\n",
    "from config import *\n",
    "from data_utils import retrieve_processed_datasets\n",
    "from model_utils import (\n",
    "    initialize_all_models,\n",
    "    train_single_model,\n",
    "    evaluate_model_predictions,\n",
    "    perform_cross_validation,\n",
    "    extract_feature_importance,\n",
    "    save_trained_model,\n",
    "    create_model_comparison_table,\n",
    "    perform_cv_all_models\n",
    ")\n",
    "from evaluation_utils import (\n",
    "    calculate_all_metrics,\n",
    "    create_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_precision_recall_curve,\n",
    "    compare_multiple_roc_curves,\n",
    "    generate_classification_report,\n",
    "    create_metrics_summary_table\n",
    ")\n",
    "from visualization import plot_feature_importance_horizontal\n",
    "\n",
    "# Setting visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Working Directory: {Path.cwd()}\")\n",
    "print(f\"Random Seed: {SEED_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93bf66d-2839-428f-aa25-e66819bdcb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING PROCESSED DATA...\n",
      "Loading processed data from C:\\Users\\Ashutosh\\Documents\\Projects\\beyond-smote-evaluation\\data\\processed...\n",
      "Datasets loaded successfully\n",
      "Training shape: (800000, 28)\n",
      "Testing shape: (200000, 28)\n",
      "\n",
      "Data loaded successfully!\n",
      "Training set shape: (800000, 28)\n",
      "Test set shape: (200000, 28)\n",
      "\n",
      "Class Distribution in Training Set:\n",
      "  Class 1: 423,738 samples (52.97%)\n",
      "  Class 0: 376,262 samples (47.03%)\n",
      "\n",
      "Class Distribution in Test Set:\n",
      "  Class 1: 105,935 samples (52.97%)\n",
      "  Class 0: 94,065 samples (47.03%)\n",
      "\n",
      "Imbalance Ratio: 0.888:1\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Loading Processed Data from Notebook 01\n",
    "# Loading the cleaned and scaled training/test data\n",
    "\n",
    "print(\"LOADING PROCESSED DATA...\")\n",
    "\n",
    "# Loading processed datasets using utility function\n",
    "X_train, X_test, y_train, y_test = retrieve_processed_datasets(file_prefix='higgs')\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Verifying class distribution\n",
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "train_dist = y_train.value_counts()\n",
    "for class_label, count in train_dist.items():\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"  Class {int(class_label)}: {count:,} samples ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\nClass Distribution in Test Set:\")\n",
    "test_dist = y_test.value_counts()\n",
    "for class_label, count in test_dist.items():\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    print(f\"  Class {int(class_label)}: {count:,} samples ({percentage:.2f}%)\")\n",
    "\n",
    "# Calculating imbalance ratio\n",
    "minority_count = train_dist.min()\n",
    "majority_count = train_dist.max()\n",
    "imbalance_ratio = minority_count / majority_count\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.3f}:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab79e966-24e8-4311-b305-63862db980b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING BASELINE MODELS...\n",
      "\n",
      "Initialized 5 models:\n",
      "  1. logistic_regression: LogisticRegression\n",
      "  2. random_forest: RandomForestClassifier\n",
      "  3. xgboost: XGBClassifier\n",
      "  4. svm: SVC\n",
      "  5. mlp: MLPClassifier\n",
      "\n",
      "Model Configurations:\n",
      "\n",
      "1. Logistic Regression:\n",
      "   - Max iterations: 1000\n",
      "   - Solver: lbfgs\n",
      "\n",
      "2. Random Forest:\n",
      "   - N estimators: 100\n",
      "   - Max depth: 20\n",
      "\n",
      "3. XGBoost:\n",
      "   - N estimators: 100\n",
      "   - Learning rate: 0.1\n",
      "\n",
      "4. Support Vector Machine:\n",
      "   - Kernel: rbf\n",
      "   - Probability: True\n",
      "\n",
      "5. Multi-Layer Perceptron:\n",
      "   - Hidden layers: (100, 50)\n",
      "   - Activation: relu\n",
      "\n",
      "All models ready for training on original imbalanced data!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initializing All Baseline Models\n",
    "# Creating instances of all 5 sklearn models WITHOUT class weights\n",
    "# Models: Logistic Regression, Random Forest, XGBoost, SVM, MLP\n",
    "# I am using original imbalanced data to establish baseline performance\n",
    "\n",
    "print(\"INITIALIZING BASELINE MODELS...\")\n",
    "\n",
    "# Initializing all models without class weights (true baseline)\n",
    "baseline_models = initialize_all_models(use_class_weights=False)\n",
    "\n",
    "print(f\"\\nInitialized {len(baseline_models)} models:\")\n",
    "for i, (model_name, model) in enumerate(baseline_models.items(), 1):\n",
    "    print(f\"  {i}. {model_name}: {type(model).__name__}\")\n",
    "\n",
    "print(\"\\nModel Configurations:\")\n",
    "print(\"\\n1. Logistic Regression:\")\n",
    "print(f\"   - Max iterations: {LOGIT_CONFIG['max_iter']}\")\n",
    "print(f\"   - Solver: {LOGIT_CONFIG['solver']}\")\n",
    "\n",
    "print(\"\\n2. Random Forest:\")\n",
    "print(f\"   - N estimators: {RF_CONFIG['n_estimators']}\")\n",
    "print(f\"   - Max depth: {RF_CONFIG['max_depth']}\")\n",
    "\n",
    "print(\"\\n3. XGBoost:\")\n",
    "print(f\"   - N estimators: {XGB_CONFIG['n_estimators']}\")\n",
    "print(f\"   - Learning rate: {XGB_CONFIG['learning_rate']}\")\n",
    "\n",
    "print(\"\\n4. Support Vector Machine:\")\n",
    "print(f\"   - Kernel: {SVM_CONFIG['kernel']}\")\n",
    "print(f\"   - Probability: {SVM_CONFIG['probability']}\")\n",
    "\n",
    "print(\"\\n5. Multi-Layer Perceptron:\")\n",
    "print(f\"   - Hidden layers: {MLP_CONFIG['hidden_layer_sizes']}\")\n",
    "print(f\"   - Activation: {MLP_CONFIG['activation']}\")\n",
    "\n",
    "print(\"\\nAll models ready for training on original imbalanced data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729e5387-11a1-493d-ac55-ea409b558c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1/5: LOGISTIC REGRESSION:\n",
      "Training Logistic Regression...\n",
      "Training completed in 3.34 seconds\n",
      "Evaluating Logistic Regression...\n",
      "Prediction completed in 0.0286 seconds\n",
      "\n",
      "Logistic Regression Performance:\n",
      "  Accuracy: 0.6414\n",
      "  Precision: 0.6390\n",
      "  Recall: 0.7425\n",
      "  F1-Score: 0.6869\n",
      "  AUC-ROC: 0.6850\n",
      "  AUC-PR: 0.6832\n",
      "  G-Mean: 0.6259\n",
      "  MCC: 0.2771\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Training Logistic Regression (Baseline)\n",
    "# Training linear model as simplest baseline\n",
    "\n",
    "print(\"MODEL 1/5: LOGISTIC REGRESSION:\")\n",
    "\n",
    "# Training logistic regression\n",
    "lr_model, lr_train_time = train_single_model(\n",
    "    model=baseline_models['logistic_regression'],\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model_name='Logistic Regression',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluating on test set\n",
    "lr_results = evaluate_model_predictions(\n",
    "    model=lr_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name='Logistic Regression',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Calculating comprehensive metrics\n",
    "lr_metrics = calculate_all_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=lr_results['y_pred'],\n",
    "    y_proba=lr_results['y_proba']\n",
    ")\n",
    "\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(f\"  Accuracy: {lr_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {lr_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {lr_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {lr_metrics['f1_score']:.4f}\")\n",
    "print(f\"  AUC-ROC: {lr_metrics['auc_roc']:.4f}\")\n",
    "print(f\"  AUC-PR: {lr_metrics['auc_pr']:.4f}\")\n",
    "print(f\"  G-Mean: {lr_metrics['g_mean']:.4f}\")\n",
    "print(f\"  MCC: {lr_metrics['mcc']:.4f}\")\n",
    "\n",
    "# Storing results for comparison\n",
    "baseline_results = {\n",
    "    'logistic_regression': {\n",
    "        'model': lr_model,\n",
    "        'metrics': lr_metrics,\n",
    "        'predictions': lr_results['y_pred'],\n",
    "        'probabilities': lr_results['y_proba'],\n",
    "        'training_time': lr_train_time\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0b6277-4ed4-48eb-9c3c-c8ade92ba7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 2/5: RANDOM FOREST\n",
      "Training Random Forest...\n",
      "Training completed in 72.45 seconds\n",
      "Evaluating Random Forest...\n",
      "Prediction completed in 1.8143 seconds\n",
      "\n",
      "Random Forest Performance:\n",
      "  Accuracy: 0.7318\n",
      "  Precision: 0.7420\n",
      "  Recall: 0.7568\n",
      "  F1-Score: 0.7493\n",
      "  AUC-ROC: 0.8130\n",
      "  AUC-PR: 0.8286\n",
      "  G-Mean: 0.7297\n",
      "  MCC: 0.4611\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Training Random Forest (Baseline)\n",
    "# Training ensemble tree-based model\n",
    "# Good performance is expected because it naturally handles imbalance better\n",
    "\n",
    "print(\"MODEL 2/5: RANDOM FOREST\")\n",
    "\n",
    "# Training random forest\n",
    "rf_model, rf_train_time = train_single_model(\n",
    "    model=baseline_models['random_forest'],\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model_name='Random Forest',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluating on test set\n",
    "rf_results = evaluate_model_predictions(\n",
    "    model=rf_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name='Random Forest',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Calculating comprehensive metrics\n",
    "rf_metrics = calculate_all_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=rf_results['y_pred'],\n",
    "    y_proba=rf_results['y_proba']\n",
    ")\n",
    "\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"  Accuracy: {rf_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {rf_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {rf_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {rf_metrics['f1_score']:.4f}\")\n",
    "print(f\"  AUC-ROC: {rf_metrics['auc_roc']:.4f}\")\n",
    "print(f\"  AUC-PR: {rf_metrics['auc_pr']:.4f}\")\n",
    "print(f\"  G-Mean: {rf_metrics['g_mean']:.4f}\")\n",
    "print(f\"  MCC: {rf_metrics['mcc']:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "baseline_results['random_forest'] = {\n",
    "    'model': rf_model,\n",
    "    'metrics': rf_metrics,\n",
    "    'predictions': rf_results['y_pred'],\n",
    "    'probabilities': rf_results['y_proba'],\n",
    "    'training_time': rf_train_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7dffa7f-02ad-478a-934e-38761de07b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 3/5: XGBOOST\n",
      "Training XGBoost...\n",
      "Training completed in 4.33 seconds\n",
      "Evaluating XGBoost...\n",
      "Prediction completed in 0.0820 seconds\n",
      "\n",
      "XGBoost Performance:\n",
      "  Accuracy: 0.7303\n",
      "  Precision: 0.7428\n",
      "  Recall: 0.7509\n",
      "  F1-Score: 0.7468\n",
      "  AUC-ROC: 0.8109\n",
      "  AUC-PR: 0.8264\n",
      "  G-Mean: 0.7287\n",
      "  MCC: 0.4584\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training XGBoost (Baseline)\n",
    "# Training gradient boosting model\n",
    "# It is often the best performer and handles imbalance reasonably but has slower training\n",
    "\n",
    "print(\"MODEL 3/5: XGBOOST\")\n",
    "\n",
    "# Training XGBoost\n",
    "xgb_model, xgb_train_time = train_single_model(\n",
    "    model=baseline_models['xgboost'],\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model_name='XGBoost',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluating on test set\n",
    "xgb_results = evaluate_model_predictions(\n",
    "    model=xgb_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name='XGBoost',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Calculating comprehensive metrics\n",
    "xgb_metrics = calculate_all_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=xgb_results['y_pred'],\n",
    "    y_proba=xgb_results['y_proba']\n",
    ")\n",
    "\n",
    "print(\"\\nXGBoost Performance:\")\n",
    "print(f\"  Accuracy: {xgb_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {xgb_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {xgb_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {xgb_metrics['f1_score']:.4f}\")\n",
    "print(f\"  AUC-ROC: {xgb_metrics['auc_roc']:.4f}\")\n",
    "print(f\"  AUC-PR: {xgb_metrics['auc_pr']:.4f}\")\n",
    "print(f\"  G-Mean: {xgb_metrics['g_mean']:.4f}\")\n",
    "print(f\"  MCC: {xgb_metrics['mcc']:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "baseline_results['xgboost'] = {\n",
    "    'model': xgb_model,\n",
    "    'metrics': xgb_metrics,\n",
    "    'predictions': xgb_results['y_pred'],\n",
    "    'probabilities': xgb_results['y_proba'],\n",
    "    'training_time': xgb_train_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c1501a-fe27-4901-a654-96d97c3c61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 4/5: SUPPORT VECTOR MACHINE\n",
      "Training SVM...\n",
      "Training completed in 1254.29 seconds\n",
      "Evaluating SVM...\n",
      "Prediction completed in 50.6166 seconds\n",
      "\n",
      "SVM Performance:\n",
      "  Accuracy: 0.5343\n",
      "  Precision: 0.6010\n",
      "  Recall: 0.3596\n",
      "  F1-Score: 0.4500\n",
      "  AUC-ROC: 0.5767\n",
      "  AUC-PR: 0.5906\n",
      "  G-Mean: 0.5127\n",
      "  MCC: 0.0973\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training Support Vector Machine (Baseline)\n",
    "# Training kernel-based classifier\n",
    "\n",
    "print(\"MODEL 4/5: SUPPORT VECTOR MACHINE\")\n",
    "\n",
    "# Training SVM\n",
    "svm_model, svm_train_time = train_single_model(\n",
    "    model=baseline_models['svm'],\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model_name='SVM',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluating on test set\n",
    "svm_results = evaluate_model_predictions(\n",
    "    model=svm_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name='SVM',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Calculating comprehensive metrics\n",
    "svm_metrics = calculate_all_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=svm_results['y_pred'],\n",
    "    y_proba=svm_results['y_proba']\n",
    ")\n",
    "\n",
    "print(\"\\nSVM Performance:\")\n",
    "print(f\"  Accuracy: {svm_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {svm_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {svm_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {svm_metrics['f1_score']:.4f}\")\n",
    "print(f\"  AUC-ROC: {svm_metrics['auc_roc']:.4f}\")\n",
    "print(f\"  AUC-PR: {svm_metrics['auc_pr']:.4f}\")\n",
    "print(f\"  G-Mean: {svm_metrics['g_mean']:.4f}\")\n",
    "print(f\"  MCC: {svm_metrics['mcc']:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "baseline_results['svm'] = {\n",
    "    'model': svm_model,\n",
    "    'metrics': svm_metrics,\n",
    "    'predictions': svm_results['y_pred'],\n",
    "    'probabilities': svm_results['y_proba'],\n",
    "    'training_time': svm_train_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22bc7523-58c8-403e-ae8f-e0058a349295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 5/5: MULTI-LAYER PERCEPTRON\n",
      "Training MLP...\n",
      "Training completed in 301.27 seconds\n",
      "Evaluating MLP...\n",
      "Prediction completed in 0.4166 seconds\n",
      "\n",
      "MLP Performance:\n",
      "  Accuracy: 0.7546\n",
      "  Precision: 0.7644\n",
      "  Recall: 0.7758\n",
      "  F1-Score: 0.7701\n",
      "  AUC-ROC: 0.8378\n",
      "  AUC-PR: 0.8506\n",
      "  G-Mean: 0.7529\n",
      "  MCC: 0.5070\n",
      "ALL 5 BASELINE MODELS TRAINED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Training Multi-Layer Perceptron (Baseline)\n",
    "# Training neural network with sklearn\n",
    "\n",
    "print(\"MODEL 5/5: MULTI-LAYER PERCEPTRON\")\n",
    "\n",
    "# Training MLP\n",
    "mlp_model, mlp_train_time = train_single_model(\n",
    "    model=baseline_models['mlp'],\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model_name='MLP',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Evaluating on test set\n",
    "mlp_results = evaluate_model_predictions(\n",
    "    model=mlp_model,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name='MLP',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Calculating comprehensive metrics\n",
    "mlp_metrics = calculate_all_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=mlp_results['y_pred'],\n",
    "    y_proba=mlp_results['y_proba']\n",
    ")\n",
    "\n",
    "print(\"\\nMLP Performance:\")\n",
    "print(f\"  Accuracy: {mlp_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {mlp_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {mlp_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {mlp_metrics['f1_score']:.4f}\")\n",
    "print(f\"  AUC-ROC: {mlp_metrics['auc_roc']:.4f}\")\n",
    "print(f\"  AUC-PR: {mlp_metrics['auc_pr']:.4f}\")\n",
    "print(f\"  G-Mean: {mlp_metrics['g_mean']:.4f}\")\n",
    "print(f\"  MCC: {mlp_metrics['mcc']:.4f}\")\n",
    "\n",
    "# Storing results\n",
    "baseline_results['mlp'] = {\n",
    "    'model': mlp_model,\n",
    "    'metrics': mlp_metrics,\n",
    "    'predictions': mlp_results['y_pred'],\n",
    "    'probabilities': mlp_results['y_proba'],\n",
    "    'training_time': mlp_train_time\n",
    "}\n",
    "\n",
    "print(\"ALL 5 BASELINE MODELS TRAINED SUCCESSFULLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053373bc-6c5a-4ce3-91b0-2a97aefac473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
